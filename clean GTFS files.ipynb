{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baca5fa8-a259-4446-8b4f-f64d4de83b1c",
   "metadata": {},
   "source": [
    "### The following code converts GTFS files\n",
    "## For GTFS files with calendar.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d612f-add8-47fa-90aa-719be2534656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV files\n",
    "calendar = pd.read_csv('calendar.txt')\n",
    "trips = pd.read_csv('trips.txt')\n",
    "stop_times = pd.read_csv('stop_times.txt')\n",
    "stops = pd.read_csv('stops.txt')\n",
    "routes = pd.read_csv('routes.txt')\n",
    "\n",
    "# Merge dataframes\n",
    "merged = trips.merge(calendar, on='service_id').merge(stop_times, on='trip_id').merge(stops, on='stop_id').merge(routes, on='route_id')\n",
    "\n",
    "calendar_service_id = set(calendar['service_id'])\n",
    "\n",
    "# Calculate the number of stops in a normal week for each stop\n",
    "merged['week_stops'] = merged['monday'] + merged['tuesday'] + merged['wednesday'] + merged['thursday'] + merged['friday'] + merged['saturday'] + merged['sunday']\n",
    "\n",
    "print(merged['week_stops'].unique())\n",
    "\n",
    "# Group by route_type and stop_id, summing the week_stops\n",
    "grouped = merged.groupby(['route_type', 'stop_id']).agg({'week_stops': 'sum', 'stop_lat': 'first', 'stop_lon': 'first', 'stop_name': 'first'}).reset_index()\n",
    "\n",
    "# Write the results to separate output files for each route_type\n",
    "for route_type in grouped['route_type'].unique():\n",
    "    output = grouped[grouped['route_type'] == route_type]\n",
    "    output.to_csv(f'output_route_type_{route_type}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba9c23-0e3e-4228-9924-47f59eb4ec95",
   "metadata": {},
   "source": [
    "## For GTFS files with calendar_dates.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6aa53-53e4-4e62-bfe1-c6805ffd9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Read CSV files\n",
    "trips = pd.read_csv(\"trips.txt\")\n",
    "stop_times = pd.read_csv(\"stop_times.txt\")\n",
    "stops = pd.read_csv(\"stops.txt\")\n",
    "routes = pd.read_csv(\"routes.txt\")\n",
    "calendar_dates = pd.read_csv(\"calendar_dates.txt\")\n",
    "\n",
    "# Convert the 'date' column to a pandas datetime object\n",
    "calendar_dates['date'] = pd.to_datetime(calendar_dates['date'], format='%Y%m%d')\n",
    "\n",
    "# Create a new column with the day of the week in text format\n",
    "calendar_dates['day'] = calendar_dates['date'].dt.day_name()\n",
    "\n",
    "service_count = calendar_dates.groupby('service_id')['day'].nunique().reset_index()\n",
    "\n",
    "# Merge DataFrames\n",
    "merged = trips.merge(stop_times, on='trip_id')\n",
    "merged = merged.merge(routes, on='route_id')\n",
    "merged = merged.merge(stops, on='stop_id')\n",
    "merged = merged.merge(service_count, on='service_id')\n",
    "\n",
    "for route_type in merged['route_type'].unique():\n",
    "    # Filter only route type of interest\n",
    "    result = merged.loc[merged['route_type'] == route_type]\n",
    "    \n",
    "    # Group by stop_id and sum the day value\n",
    "    grouped = result.groupby('stop_id').agg({'day': 'sum', 'stop_lat': 'first', 'stop_lon': 'first', 'stop_name': 'first', 'stop_id': 'first', 'route_type': 'first'})\n",
    "    \n",
    "    #Write to CSV\n",
    "    grouped.to_csv(f\"route_type_{route_type}_dates.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
